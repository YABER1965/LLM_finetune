---
title: QEUR23_PHI3CHR11 : 閑話休題～TTTNN
date: 2024-06-12
tags: ["QEUシステム", "メトリックス", "Python言語", "LLM", "データセット", "Fine-tuning", "イノベーション","PHI-2"]
excerpt: LLMのファインチューニングを最適化する
---

## QEUR23_PHI3CHR11 : 閑話休題～TTTNN

## ～ 注意：かなり前の古い議論です ～

### T法学習型ﾆｭｰﾗﾙﾈｯﾄﾜｰｸ(TTTNN: Training with T method Two for Neural Network)


**【背景技術】**
**Technology background**

1980年代に提案されたニューラルネット(NN)は、2010年代からディープラーニング(DL) 技術に発展して科学技術の多くの分野に普及してきました。ディープラーニングは従来の統計的手法では不可能であった「（応答変数）多次元（説明変数）多変数」、さらに高次関数の当てはめが可能となる画期的な技術です。
Neural Networks (NNs), which were proposed in the 1980s, have evolved into Deep Learning (DL) tech-nology since the 2010s to get popularity in many fields of science and technology. Deep learning is a revo-lutionary technology for fitting "multidimensional (response variable), multivariate (explanatory varia-ble)" and even higher-order functions, which was not possible with conventional statistical methods.

**(図1：ニューラルネットからディープラーニングへ)**
**(Fig. 1: From Neural Networks to Deep Learning)**

![imageJRF1-31-1](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-1.jpg)

ディープラーニングの当てはめの考え方は、従来の統計的手法(例えば重回帰分析)のやりかたとは全く異なります。重回帰分析にはデータ数（データ数は説明変数の数より多いこと、できれば3倍以上）の制約がゆるくなっています。これはディープラーニングが逆行列を使っていないためです。
Deep learning's approach to fitting is quite different from the way traditional statistical methods (e.g. mul-tivariant regression analysis) work. Multivariant regression analysis has a looser constraint on the number of data (the number of data must be larger than the number of explanatory variables, preferably three times larger). This is because deep learning does not use inverse matrix.

**(図2:重回帰分析の線形式表現)**
**(Fig. 2: Linear equation representation of multivariant regression analysis)**

![imageJRF1-31-2](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-2.jpg)

しかしながら、ディープラーニングはモデルを前提としない当てはめ手法であるため、いくつかの欠点があります。その最大の問題の一つは「変数を選択」するための仕組みがないことです。逆に、そうであるからこそ「ディープラーニングの見た目の当てはめ力が良い」とも言えます。（※ディープラーニングについても、「クロスバリデーション」のような再現性を確保するためのオプション手法はあります。ここでの問題はその手法の「根本」には発想がないことです。）
However, since deep learning has a weak point because it is a kind of fitting method that does not assume a model. One of its biggest problems is that it has no scheme for "selecting variables". On the other hand, this is the reason why "the apparent fitting power of deep learning is good". (*For deep learning, there are optional methods to ensure reproducibility, such as "cross-validation". The problem here is that it does not has such idea originally.). 

**(図3:重回帰分析の「変数選択」)**
**(Fig. 3: Variable selection in multivariant regression analysis)**

![imageJRF1-31-3](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-3.jpg)

**【発明が解決しようとする課題】**
**Problems to be solved by this invention.**

ディープラーニングは優秀な予測手法ではありますが状況によっては予期せぬ誤差が発生する可能性があり、その原因の一つは説明変数の相関です。項目間相関は、図4に示すように説明変数の間に強い相関がある場合です。説明変数に相関がある場合には、前処理なしで学習すると予測が不安定になりやすくなります。
Deep learning is an excellent prediction method, but under some situations, unexpected errors might be occurred, and one of the causes is correlation between explanatory variables. Inter-Items-Correlation mean there is a strong correlation between the explanatory variables, as shown in the figure 4. When there is cor-relation in the explanatory variables, the prediction likely to be unstable if it is learned without any pre-process.

**(図4: 説明変数間の相関)**
**(Fig. 4: Correlation between explanatory variables)**

![imageJRF1-31-4](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-4.jpg)

相関が現実問題に表れる事例として素材産業があります（図5は製鉄業のケースです）。原材料には原料の使用目的としての主成分元素以外にも、意図しない不純物（多くの場合は悪影響を与える）が存在します。原材料の生産地が違うと不純物の種類や含有量がことなります。このようなプロセスでは原材料の主成分元素がもたらす特性と、不純物がもたらす特性の間に強い相関が発生します。
An example which correlation may induce a real problem is in the materials industry (Figure 5 is a case of the steel industry). In addition to the main elements intended for use in raw materials, there are also unin-tended impurities (which often have adverse effects) in raw materials. Different raw materials come from different places, the type and content of impurities will be different. In above processes, a strong correla-tion will be appeared between characteristics by main component of the raw material and one induced by impurities.

**(図5: 相関の事例)**
**(Fig. 5: Examples of correlation)**

![imageJRF1-31-5](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-5.jpg)

このような状況でプロセス制御のためにディープラーニングをそのまま使うと問題が発生しやすくなる可能性があります。例えば、本来使っている原料生産地の供給にトラブルが起きたので別の産地の原料に切り替えた場合、そのプロセスにトラブルが発生するかもしれません。その原因の一つは、制御コンピュータをチューニングする時にプロセスが本来の原産地の原料で最適化されており、ほかの原料が来た時に予期せぬ偏差が生じたことが考えられます。
If deep learning is used inconsiderably for process control in such a situation, some problems may occur. For example, the process may have a problem if a raw material from different origin is introduced because of problem in the supply of the original raw material production area. One of the reasons is that the pro-cess was optimized for the material from the origin when tuning the control computer, and unexpected de-viations occurred when other raw materials had been applied.

「相関のある変数は特に重要なモノのみを残し、あとは捨てる」という予測ノウハウは広く普及されています。今までの重回帰分析による当てはめでは、この考え方が一般的でした。重回帰分析の当てはめ力はもともと弱いので、単純な変数選択で精度を確保することができました。しかし、ディープラーニングによる学習では従来は活用できなかった非線形特性や交互作用も当てはめることができるので、相関のある変数を捨てるのはもったいないかもしれません。
The prediction knowhow, "selecting the most important correlated variables only and discarding the rest" has been widely used. This approach has been common in multivariant regression analysis since the fitting power of multivariant regression analysis is weak comparatively, simple variable selection is enough to ensure accuracy. However, it may not be good idea to discard variables with correlation because deep learning can also fit nonlinear characteristics and interactions that could not be utilized by conventional scheme.

**【課題を解決するための手段】**
**Means to solve problems.**

本発明では重回帰分析に近い機能をもつT法とディープラーニングを組み合わせて予測します。ここで、T法は説明変数の数に制限がなく、非常に少ないデータ数（単位空間が1データ以上、信号空間が3データ以上）でも計算できます。さらに、T法には単位空間という、ユーザーが特に予測精度を上げたい位置を任意に設定できる特長があります。
This invention combines T-method, which has similar functions to multivariant regression analysis, and deep learning to make predictions. Whereas, T-method has no limitation on the number of explanatory var-iables to calculate with a very small number of data (more than one data for unit space and more than three data for signal space are required). In addition, T-method has the feature that the user can arbitrarily set unit space on the location where user especially wants to improve the prediction accuracy.

**(図6:  T法の特性)**
**(Fig. 6:  Characteristics of T-method)**

![imageJRF1-31-6](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-6.jpg)

すでに述べたように、T法は少ないデータ数でも解析が可能なので、ユーザーが特に注目している小さなデータ群や実験値を使用して予測したい場合に効果的です。本発明では、データの種類を図7のように分けることにします。
As already mentioned, T-method can be used to analyze a small number of data, so it is effective when the user wants to use a tiny group of data or experimental values with particular interest to make a prediction. In this invention, classification of the data types as shown in Fig. 7 is shown below.

**(図7: 学習データの分類)**
**(Fig. 7: Classification of training data)**

![imageJRF1-31-7](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-7.jpg)

本発明では「第1段階学習」でT法を使い、「第2段階学習」ではニューラルネットを使います。本発明の予測手法の考え方をデータの分布で表現すると図8のようになります。まずT法で単位空間で回帰の重点位置を設定して信号空間でスケールを作成し、その後ディープラーニングを使って大量のデータを学習します。
In this invention, T-method is applied for the "first step learning" and neural net used for the "second step learning". The concept of our prediction method is expressed in terms of data distribution as shown in Fig-ure 8. First, T-method is used to set a focus on regression with unit space to create a scale with signal space, and then deep learning is applied to learn with a large amount of data.

**(図8: 本発明の回帰予測の考え方)**
**(Fig. 8: A concept of regression prediction in this invention)**

![imageJRF1-31-8](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-8.jpg)

計算手法としては、応答変数Yを図9のようにYA、YB、YCの3成分に分けます。ここで、YAは線形成分を示し、YBとYCはそれぞれ交互作用と非線形成分を示します。YAの予測はT法で行い、YBとYCの予測はディープラーニングで行います。
As for the calculation methodology, the response variable Y is classified into the following three compo-nents, YA, YB, and YC, as shown in Fig. 9. The prediction of YA is created by T method, while the value of YB and YC is predicted by deep learning.

**(図9: 応答変数Yの分解)**
**(Fig. 9: Decomposition of response variable Y)**

![imageJRF1-31-9](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-9.jpg)

**【実施例_1】**
**Example_1**

本章では本発明(2段階学習)の実施例を示します。ここで使用するデータはUCIの自動車の燃費に関するデータセットです。本データの内容の一部を図10A、B、Cに示します。ここで、コラムのMPGは燃費を示し、Originはメーカの所在国を示します(図11)。
This chapter shows an example of this invention (two-stage learning). The data used here is the UCI's data set on automobile fuel efficiency. Some of the contents of this data are shown in Figure 10a, b, and c. Whereas, a column named MPG indicates the fuel consumption, and Origin indicates countries where the manufacturer is located (Figure 11).

**（図10A ：AUTO-MPG生データ）**
**(Fig. 10A: Raw data of AUTO_MPG)**

![imageJRF1-31-10](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-10.jpg)

**（図10B ：AUTO-MPG生データ）**
**(Fig. 10B: Raw data of AUTO_MPG)**

![imageJRF1-31-11](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-11.jpg)

**（図10C ：AUTO-MPG生データ）**
**(Fig. 10C: Raw data of AUTO_MPG)**

![imageJRF1-31-12](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-12.jpg)

**（図11 ： メーカ所在国別燃費比較）**
**(Fig. 11: Comparison of fuel efficiency sorted by country of manufacturer)**

![imageJRF1-31-13](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-13.jpg)

第1段階学習ではメーカ所在国がJapanであるデータを使うこととします。T法解析に当たり、単位空間を図12のように選択するとSN比と感度は図13のようになりました。
When the unit space is selected as shown in Fig. 12 for T-method analysis, SN ratio and sensitivity are shown in Fig. 13.

**（図12 ： 単位空間の選択）**
**(Fig. 12: Selecting unit space)**

![imageJRF1-31-14](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-14.jpg)

**（図13 ： 感度とSN比）**
**(Fig. 13: Sensitivity and SN ratio)**

![imageJRF1-31-15](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-15.jpg)

T法では説明変数間に相関がある(独立ではない)と予測精度が低くなりますので、相関マトリックスを作成して相関を確認しました(図14)。今回の事例では、1つの変数だけと相関が高い説明変数は排除し、2つの以上の変数と相関があるものを予測に使用しました。
T-method reduces prediction accuracy if correlation between explanatory variables is high (not independ-ent). Thus, a correlation matrix is shown below to check the correlation (Figure 14). In this case, an ex-planatory variable with high correlation to one variable were eliminated, and one correlated with two or more variables were used for prediction.

**（図14 ： 学習データの相関行列）**
**(Fig. 14: Correlation matrix of training data)**

![imageJRF1-31-16](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-16.jpg)

T法予測による精度の検証結果を図15に示します。ここでは、Japanのみのデータで学習し、検証しています。
Figure 15 shows the results of verifying the accuracy of T-method prediction. Whereas, Japan data only is used for train and validation.

**（図15： T法の予測精度の検証結果）**
**(Fig. 15: Validation results of the prediction accuracy of T-method)**

![imageJRF1-31-17](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-17.jpg)

ディープラーニングを使った第2段階学習に進みます。第2段階学習ではEurope-US-Japanのすべてのデータが対象になります。Y値（応答変数）は式1で規準化(図16)しました。名義変量(Europe:1-US:2-Japan:3)はOne-Hot表現とし、その他の説明変数はT法の単位空間で規準化しています。
Now, the second step of learning using deep learning is conducted. The Y-values (response variables) were normalized by Equation 1 (Fig. 16). The nominal variables (Europe:1-US:2-Japan:3) are represented with One-Hot expression, and the other explanatory variables are normalized by unit space of T-method.

***第2段階の規準化後Y値） = （生データ値） - （第1段階のY予測値）   ： 式１***
***(Normalized Y-value on the second step) = (raw data value) - (Y-predicted value on the first step): Equation 1.***

**（図16： 第2段階規準化後の学習データ）**
**(Fig. 16: Training data after normalization on the second step)**

![imageJRF1-31-18](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-18.jpg)

これらの規準化されたデータをディープラーニングで学習した結果を図17に示します。ディープラーニングなので、T法や重回帰分析では予測ができない非線形や交互作用についても当てはめされていることがわかります。
The results of training these normalized data with deep learning is shown ifg17. Thank to deep learning, it is shown that nonlinearities and interactions component that cannot be predicted by the T-method or mul-tiple regression analysis.

**（図17：第2段階規準化データの当てはめ結果）**
**(Fig. 17: Fitting results on the second step criterion data)**

![imageJRF1-31-19](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-19.jpg)

生データと比較した、第1段階学習の精度検証結果を図18に示し、第2段階学習の精度検証結果を図19に示しました。本発明(第2段階学習)では、T法や重回帰分析では解決できない非線形と交互作用による誤差を改善しています。
The accuracy validation results on the first step learning compared to the raw data are shown in Fig. 18, and one on the second step learning are shown in Figure 19. This invention (the second step learning) im-proves the errors due to nonlinearity and interaction, which cannot be solved by T-method or multivariant regression analysis.

**(図18：第1段階学習での予測精度)**
**(Fig. 18: Prediction accuracy on the first step learning)**

![imageJRF1-31-20](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-20.jpg)

**(図19：第2段階学習での予測精度)**
**(Fig. 19: Prediction accuracy in second step learning)**

![imageJRF1-31-21](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-21.jpg)

本発明では、説明変数間に相関がある場合でも、第2段階学習で誤差を発生しないように工夫されています。第2段階学習のY値の定義（式1）によれば、T法計算において重要でないと判断した説明変数の変動に対して、第2段階のY値は応答しません(ほとんど0に近くなる)。つまり、T法でプロセスの基本構造を設定したことにより、ニューラルネットの予測値は説明変数の相関に対してロバストになります。
This invention is designed to eliminate errors on the second step learning even no matter correlation among explanatory variables. According to the definition of Y-value on the second step learning (Equation 1), Y-value on the second step does not respond (it is almost zero) regardless variation of explanatory vari-ables that are classified to be unimportant for T-method calculation. In other words, a structure based on T-method is set up to make prediction of the neural network more robust to the correlation of explanatory variables.

***（第2段階の規準化後Y値） = （生データ値） - （第1段階の予測Y値）   ： 式１(再掲)**
***(Second step post-criterion Y-value) = (Raw data value) - (First step predicted Y-value): Equation 1 (restated).***

**（図14(再掲) ：データの相関行列）**
**(Figure 14 (restated): Correlation matrix of the data)**

![imageJRF1-31-22](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-22.jpg)

**【産業上の利用可能性】**
**Industrial applicability**

本発明は、ディープラーニングを使った「教師あり学習(図20)」に使用可能です。ただし、著しい効果が見られるのは従来は重回帰分析で予測していたが、ディープラーニングに変更した場合です。ディープラーニングを使うことにより、重回帰分析では当てはめられなあったYB、YC成分の予測が可能になります(図21)。
This invention can be used for many cases of "supervised learning" (Fig. 20) using deep learning. However, it generates significant effect when deep learning is applied instead of multivariant regression analysis. Deep learning can predict YB and YC components that could not be fit by multivariant regression analysis (Fig. 21). 

**（図20 ：機械学習の体系図）**
**(Fig. 20: Diagram of Machine Learning System)**

![imageJRF1-31-23](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-23.jpg)

**（図21 ：予測精度の改善）**
**(Fig. 21: Improvement of prediction accuracy)**

![imageJRF1-31-24](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-24.jpg)

さらに、本発明を「新しい事象を予測する」ために使用することもできます。例えば、新製品（マイナーチェンジ品）の特性を予測する場合を考えます（図22）。
Furthermore, this invention can be applied to "predict something new”. For example, a case of predicting characteristics of a new product (minor change product) (Fig. 22) is considered.

**（図22 ：新製品の特性予測精度の向上）**
**(Fig. 22: Improving the accuracy of predicting characteristics of new products)**

![imageJRF1-31-25](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-25.jpg)

すでに多くの生産実績のある製品系列A(製品はA1…An)があるとします。新製品An+1を作りたいが、その製品特性を予測したい。ただし、新製品の特性は製品系列Aの中でもAℓにもっとも近いであろうことが想定されています（新製品An+1が製品開発段階にあり、すでに少数のデータがある場合でも同様です）。本発明による予測は、以下の2つの特長により従来手法よりも高い精度で製品特性を予測できるでしょう。
Suppose you have a product family A (products are A1...An) that has already been produced in large num-bers. You need to produce a new product An+1 in future, and prediction is required. However, it is assumed that the characteristics of the new product will be closest to Aℓ among the product series A (this is true even if the new product An+1 is in the product development stage and a small number of data are already available). The prediction will be more accurate than conventional methods due to the following two fea-tures.

**（本発明が従来手法よりも精度が高い根拠）**
**(Reason why this invention has higher accuracy than conventional methods).**

本発明は単なるディープラーニング予測よりも予測精度が高い
  → 新製品Aｎ+1が既存製品Ａℓの特性に近いという情報が含まれています
  → ディープラーニングは学習データの誤差総和を最小にするが、本発明では単位空間によりAn+1の付近で誤差が小さくなるようにしている
This invention has higher prediction accuracy than just deep learning prediction.
  → It contains the information that the new product An+1 is close to the properties of the existing product Aℓ
  → Deep learning minimizes the sum of errors in the training data, but in this invention, unit space minimize the error near An+1.

本発明はT法や回帰分析よりも予測精度が高い
  → ディープラーニングによる予測なので、非線形、項目間の交互作用の量を予測できます
This invention has higher prediction accuracy than T-method and regression analysis.
  → Deep learning prediction can predict the amount of non-linear, item-to-item interactions.



## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “もしも、手元に学習するデータが少なくとも、TTTNNを使えば、他のデータを学習に転用できる可能性があります。”

C部長: “今のはやりの言葉でいうと**「finetune」**ですね。”

![imageJRF1-31-26](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-26.jpg)

QEU:FOUNDER ： “そうなんです。これを始めた当時はfinetuneのことを知りませんでした。いまからみれば、そうなんだよねえ・・・。まだまだ本格的なfinetuneには程遠いが・・・。”

[![MOVIE1](http://img.youtube.com/vi/witYJ6lxFvE/0.jpg)](http://www.youtube.com/watch?v=witYJ6lxFvE "日本の賃金はなぜ低いのか？")

QEU:FOUNDER ： “**「希少資源（人間のやる気）」を正しく使うことができれば、生産性向上を実現できる**のではないでしょうか。ただし、**QEUシステムの「ものの見方」はメトリックスからモデルに変化しました**。最終的な目標はTTTNNじゃないんです。”

![imageJRF1-31-27](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-27.jpg)

QEU:FOUNDER ： “今、とりくんでいる「BONSAI」プロジェクトで、モデルを使えば汎用技術構造をより簡単に実現できることがわかっています。例えば、Reasoningの出力の場合では以下のように簡単なプロンプトで表現されます。”

```python
You should read sentences of 'INSTRUCTION' and 'OUTPUT'. The user receives information in 'INSTRUCTION' to response in 'OUTPUT' with the guidance of 'REASONING'. You should write the appropriate reasoning logic. The generated logic should not be an answer to user's question itself, but it should be a hint for the user to provide better answer. You should make up the reasoning logic step by step by learning related information before responding. Please try to start each sentence with 'You should' if possible. Please write your logic(answer) within 5 sentences and within 120 words.
INSTRUCTION'''
{{ str_instruction }}
'''
OUTPUT'''
{{ str_output }}
'''
'REASONING' :
```

D先生: “確かに、モデルにプロセスへのインプットとアウトプット情報を入力し、REASONING情報を取り出しています。”

![imageJRF1-31-28](/2024-06-12-QEUR23_PHI3CHR11/imageJRF1-31-28.jpg)

D先生: “ここまでくると、ユーザーが自分が欲しいモノをプロンプトで入力すると、答えが出てきます。”

QEU:FOUNDER ： “もちろん、そのように自分にあった答えが欲しいときには、そのモデルが適切にファインチューンされていないといけないが・・・。”

C部長: “そういうときが来るといいですね。”

D先生: “今の技術では十分にできると思いますよ。我々ではできないが、誰かがやってくれるとおもいます。”

### [＞寄付のお願い(click here for buy me a cup of coffee)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER ： “まあ・・・。今回は、そういう思いで、小生が考えている**「世界観」**を敢えて言葉にしたわけです。”

