---
title: QEUR23_PHI3FBQ11:  RAG（LangChain-Cohere）を使ってディベートしてみる（Step1）
date: 2024-05-28
tags: ["QEUシステム", "メトリックス", "Python言語", "LLM", "データセット", "Fine-tuning", "イノベーション","PHI-2"]
excerpt: LLMのファインチューニングを最適化する
---

## QEUR23_PHI3FBQ11:  RAG（LangChain-Cohere）を使ってディベートしてみる（Step1）

## ～ 再出発です。最初なので、Gradioを使ってみます。 ～

D先生： “前回で、FACT_BASED_QUESTION(FBQ)のプロジェクトが終わりました。結論としては、FBQという考え方は悪くはないですね。特に、**軽量のLLMにおいて**は・・・。さて、FOUNDERは、同じテーマでもう一度プロジェクトの繰り返しをやりたいとか・・・。”

![imageJRF1-12-1](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-1.jpg)

QEU:FOUNDER ： “自分が設定したGOALに対して、敢て反対方向の意見を出してみて、それら賛成、反対の意見を総合して判断してみたい。つまり**「ディベート」**だね。あとは、**CohereのLLMという「異物」**も敢て混ぜてみたい。ただし・・・。”

![imageJRF1-12-2](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-2.jpg)

D先生： “どうやらCohereのTrial APIには**流量制限**があるようです。その点、GROKで推論する場合は少しだけ甘くなっているようですが・・・。”

![imageJRF1-12-3](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-3.jpg)

QEU:FOUNDER ： “我々のやり方は、推論の繰り返し数が多いので1つのモデルに頼れないという事情があるんですね。それでは始めましょう。今回は、前回と少しだけ違うよ・・・。”

```python
!pip install langchain
!pip install gradio
!pip install Cohere
!pip install langchain_cohere

```

D先生： “えっ？Gradioを使うんですか？”

![imageJRF1-12-4](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-4.jpg)

QEU:FOUNDER ： “我々の開発しているシステムのINPUTはConceptとGoalだけでしょ？INPUTを簡単に変えられるようにしたかったんです。それでは、改造部分のみをドン！！”

```python
# -----
# [プロジェクト初期化用,Cohere-Gradio]GroqとCohereを使って、簡単にQuestion to Question を試す
# -----
import os
import re, math, time
import gradio as gr
# ---
import pandas as pd
import numpy as np
from langchain_core.prompts import ChatPromptTemplate
# ---
# 選択してね(今回はCohere)
from langchain_cohere import ChatCohere
# -----
# 使う前にGroqとCohereに登録し、APIコードをもらってね
os.environ["COHERE_API_KEY"] = "m2W自分で撮ってね"
# -----
# COMMAND-R-PLUS
llm = ChatCohere(model="command-r-plus",temperature=0.2)
# -----
# AGIによるChain推論を行う
# -----
# システムメッセージの一覧
# -----
#sys_message_journalist = "You are a journalist who is good at gleaning relevant facts from a given question."
sys_message_AIassistant = "You are an AI assistant who is adept at providing answers in multiple languages: English, French, Russian, Arabic, Chinese, and Japanese."
#sys_message_translator = "You are translator who is fluent in multiple languages.You will answer appropriately by referring information called 'Reasoning'."
#sys_message_creator = "You are creator who create amazing content with your free ideas. You at-tract readers with your beautiful writing such as novel or advertisement. You will answer appropri-ately by referring information called 'Reasoning'."
#sys_message_logician = "You are an excellent logician and are instructing users on \"thinking pro-cedures for providing better quality reasoning to user-provided questions.\". "
# ---
# 初期設定（パイプライン）
system = sys_message_AIassistant

# ---
def generate(str_concept, str_goal):

    # ---
    human = "{text}"
    prompt = ChatPromptTemplate.from_messages([("system", system), ("human", human)])
    chain = prompt | llm

    # ---
    # INSTRUCTIONの生成
    # 以下のコンセプト（「CONCEPT」）と結論（「GOAL」）を掲げて論文を書きたい。論文の各章のタイトルを生成してください。その論文の章の数は 15 である必要があります。論文の章タイトルは「？」で終わる疑問文でなければなりません。各文の長さは20語以上、40語以下にしてください。15つの疑問文を出力する形式は「[],[],...」というリスト型式である必要があります。
    str_instruction = f"""I want to write a thesis with the following concept ("CONCEPT") and con-clusion ("GOAL"). Generate titles for each chapter of the thesis. The thesis should have 15 chapters. The chapter titles of the thesis should be interrogative sentences ending with '?'. Each sentence should be at least 20 words long and at most 40 words long. The format for outputting 15 questions must be a format of \"['Question1'],['Question2'],...\"".
    CONCEPT```
    {str_concept}
    ```
    GOAL```
    {str_goal}
    ```
    """
    # ---
    #print(str_instruction)

    # ----
    # 推論する
    response = chain.invoke({"text": str_instruction})
    #print(response.content)

    # ----
    # Question(Step1)リストを抽出する
    str_answer = response.content

    return str_answer

# Blocksの作成
with gr.Blocks() as demo:
    # UI
    str_concept = gr.Textbox(lines=3, label="Concept", value="Please Input Concept.")
    str_goal    = gr.Textbox(lines=5, label="Goal", value="Please Input Goal.")
    output      = gr.Textbox(label="Output Box")
    Inference_btn   = gr.Button("Inference")
    # イベントハンドラー
    Inference_btn.click(fn=generate, inputs=[str_concept, str_goal], outputs=output)

# 起動
demo.launch(share=True)

```

QEU:FOUNDER（設定年齢65歳）  ： “あとは、回答がバラバラとでてきます。これを、前回までのノウハウで徐々に処理していただけるといいです。”

- 13世紀からキエフ大公国の形成までのロシアとウクライナの歴史的軌跡はどのようなもので、それがどのようにそれぞれの道を形作ったのか？
- キエフ大公国はどのように発展し、その後のロシアとウクライナの歴史にどのような影響を与えたのか？
- ロシア帝国の崩壊とブレジネフによるソ連の台頭は、ロシアとウクライナの関係にどのような影響を与えたのか？
- ソ連崩壊後のロシアとウクライナにおける重要な出来事と転換点は何であり、それが現在の状況をどのように形作ったのか？
- ソ連崩壊後のロシアとウクライナの緊張と紛争において NATO はどのような役割を果たしてきたのか？
- 西欧諸国とロシア/ウクライナの経済関係はどのように発展してきたのか、ノルド ストリーム プロジェクトの重要性は何か？
- 2014年のクリミア紛争は、2022年のロシアとウクライナの全面戦争の舞台をどの程度設定したのか？
- 2022年の戦争開始時のロシアとウクライナの当初の戦略と目標は何だったのか、そしてそれらは時間とともにどのように適応してきたのか？

D先生（設定年齢65歳） ： “・・・ん？**歴史に関する質問の量が増えました**。CONCEPTとGOALを変えましたか？”

QEU:FOUNDER ： “もちろん！せっかく新しくやり直すんだからINPUTの内容を変えますよ。参考までに、Question to QuestionのEXCELファイル出力の内容を軽く見てみましょう。”

![imageJRF1-12-5](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-5.jpg)

D先生： “まあ、基本は前回とおなじです。じゃあ、サマリーのEXCELファイルの構造も同じなんですか？”

QEU:FOUNDER ： “そこは、少しだけ変わりました。”

![imageJRF1-12-6](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-6.jpg)

QEU:FOUNDER ： “EXCELファイルにCONCEPTとGOALの情報がはいっているでしょ？これは、**次のステップでこのデータを読み取りたい**という意志なんです。他は変わらないよ。ちなみに、今回サマリーの内容を見てみましょう。”

--- 以下は、Step1 の要約文です ---
ロシアとウクライナの歴史的軌跡は、時間の経過とともに大きく分岐し、それぞれ異なる道を歩んできました。モンゴル・タタール支配下のロシアでは強力な公国が台頭し、キエフ大公国の一部であったウクライナは衰退と外国の影響に直面しました。中央集権国家の形成は、ロシアが独裁と拡張主義を受け入れ、ウクライナが競合する勢力の中で独立を求めて奮闘する中で、両国の進化を特徴づけました。文化的および宗教的影響も異なり、ロシアの正教はナショナリズムを育み、ウクライナは西洋と東洋の両方の文化の影響を受けていました。政治的および社会的違いが生まれ、ロシアの中央集権帝国はウクライナの民主的なコサックの伝統と対照的でした。これらの軌跡は、両国独自の文化と関係の基礎を築きました。

9 世紀に設立されたキエフ大公国は、ロシアとウクライナのアイデンティティを形成する上で極めて重要な役割を果たしました。ウクライナの拡大と東方正教会の採用は、ロシア正教会の基礎を築き、キリル文字を導入しました。キエフ・ルーシはウクライナの国民的アイデンティティの中心であり、キエフは象徴的に大きな重要性を持っています。キエフ・ルーシに根ざした両国の歴史的なつながりは、しばしば政治的および領土紛争の原因となり、国家建設の物語に影響を与えてきました。

ロシア帝国の崩壊とブレジネフによるソビエト連邦の台頭は、ロシアとウクライナの関係に多大な影響を及ぼしました。ウクライナは強制的にソビエト化され、国民的アイデンティティと文化が抑圧されました。中央集権的な管理と経済統合は相互依存関係を生み出し、反対意見の抑圧と人権侵害は歴史的な不満の遺産を残しました。国境と領土紛争、特にクリミアをめぐる紛争は、緊張をさらに高めました。この時期は、両国間の継続的な文化的、言語的、領土的紛争の舞台となりました。

ソ連崩壊後の時代は、両国で経済改革、政治的混乱、民主主義と権威主義への異なる道を歩んだ。ウクライナの独立は経済的課題と民主主義確立への闘争をもたらした。ロシアの道は経済危機と政治的権力闘争によって特徴づけられた。経済改革はオリガルヒの台頭につながり、政策決定に影響を与えた。クリミアとドンバスをめぐる紛争、およびウクライナの欧州統合への願望は、継続的な緊張を生み出した。プーチン政権下でのロシアの権威主義と国家主義への転換は、2022年のウクライナ侵攻で頂点に達した。

NATOはロシアとウクライナの緊張関係において複雑な役割を果たしてきた。NATOの東方拡大はロシアにとって脅威とみなされ、ウクライナは安全保障のためにNATO加盟を求めている。NATOは安全保障を保証してきたが、交渉はしばしば利害の対立によって困難に直面する。NATOの干渉と情報戦に対するロシアの認識は、その強硬な外交政策を形作っている。 NATOは西側諸国の団結とロシアの侵略への対応のプラットフォームとして機能し、世界の安全保障体制に影響を与えてきた。

西欧、ロシア、ウクライナの経済関係はエネルギーの相互依存を中心に展開している。西欧はロシアの天然ガスに依存しており、ウクライナは重要な輸送拠点となっている。ノルドストリームプロジェクトはロシアの天然ガスへの直接アクセスを提供し、輸送国としてのウクライナへの依存を軽減する。このプロジェクトは、ヨーロッパのエネルギー安全保障、地政学的ダイナミクス、ウクライナの戦略的立場に影響を及ぼしている。

2014年のクリミア紛争は2022年の全面戦争の舞台となり、地政学的状況を再形成した。ロシアによるクリミア併合とウクライナ東部の紛争は西側諸国との緊張を高め、ロシアの軍備増強と情報戦をもたらした。ウクライナの抵抗とナショナリズムは強化され、ウクライナ軍は西側諸国の支援を受けた。ロシアの戦略目標は未達成のままであり、最終的に2022年に侵攻するという決定につながった。

ロシアとウクライナの戦争は、2022年の開始以来進化してきた。ロシアの最初の迅速な作戦は、ウクライナの非武装化と「非ナチ化」を目指したもので、ウクライナは防衛と生存に重点を置いた。戦争が長引くにつれて、ロシアは東部地域に焦点を移し、残忍な包囲戦術を採用した。ウクライナは機動的な防衛と西側諸国の武器の効果的な使用で適応した。戦争は膠着状態に陥り、多数の死傷者と破壊者が出たため、双方は圧力をかけるための戦略を採用した。

ロシアに対する経済制裁は、世界経済と地政学的状況に大きな影響を及ぼした。それらは世界経済の成長の減速に寄与し、特にエネルギー市場に影響を与えた。西側諸国は制裁を課すことで団結を示し、世界統治に影響を与えた。ユダヤ人のディアスポラは人道支援を提供し、ロシアに対するより強力な行動を主張した。制裁は脱グローバリゼーションを加速させ、世界同盟を変えた。

ロシアとウクライナの紛争は、BRICS 同盟と南半球諸国の力学に影響を与えました。BRICS 諸国内に分裂を生じさせ、南半球諸国に経済的な機会と課題をもたらしました。この紛争は、地政学的再編、食糧とエネルギーの安全保障に関する懸念、多国間主義と南南協力に向けた取り組みを加速させました。

ロシアとウクライナは軍事力と戦略が大きく異なります。ロシアは、通常戦争の経験を持つ大規模で装備の整った軍隊を保有していますが、ウクライナは 2014 年以降、陸軍と非対称戦争に重点を置き、軍隊を変革してきました。ロシアは大勢の軍隊と火力に依存していますが、ウクライナは機敏性と柔軟性を重視しています。この紛争は、戦略文化と技術の革新的な使用における違いを浮き彫りにしました。

ウクライナの宗教、民族、言語の多様性は、その文化、社会、政治に深く影響を及ぼしています。宗教、民族、言語の混合は、ウクライナの活気に満ちたユニークな性格を形作り、その政治と国際関係に影響を与えています。

ウクライナにおける親ロシア派の抑圧は複雑で、ウクライナの政治情勢やロシアとの関係に影響を与えてきた。ウクライナの欧州統合への転換は親ロシア派の疎外を招いた。分離主義運動の取り締まりやロシアの影響に対抗する取り組みは人権侵害の非難を招いた。国家安全保障と市民の自由のバランスを取ることは依然として課題である。

ウクライナが抵抗を続け戦争が長引けば、人道的、経済的、地域的に壊滅的な結果を招くだろう。民間人の苦しみ、インフラの破壊、経済の荒廃が広がるだろう。紛争が長引けば軍事的エスカレーション、政治的・社会的変化、世界経済への影響が生じるリスクがある。しかし、ウクライナの回復力と団結は長期的にはその立場を強化する可能性がある。

D先生： “率直に言って、前回よりもかなり「深み」があるまとめです。おそらく、今回はより歴史を重要視しているためでしょうね。あと、親U国的なコメントも見られますね。”

QEU:FOUNDER ： “Cohere製ＬＬＭの特徴じゃない？ちなみに、CA国には非常に多くのU国出身者がいます。これはマメです・・・。カンパをお願いします。よろしくお願いします。議論を深め、FACTも生成させましょう。”

### [＞寄付のお願い(click here for buy me a cup of coffee)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

D先生： “今回は反対意見をつけるの？”

QEU:FOUNDER ： “次回のステップでは、アゲンスト(against)設定はしないですよ。”

## ～ まとめ ～

QEU:FOUNDER ： “さて、このLLMモデル（↓）は面白い。ファンになりました。”

[![MOVIE1](http://img.youtube.com/vi/mqmQ7U2I4is/0.jpg)](http://www.youtube.com/watch?v=mqmQ7U2I4is "Aya: Instruction Style Data, with Vu Minh Chien")

C部長 : “J国も、V国も**マイナー**だな。データセットから見て・・・。”

![imageJRF1-12-7](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-7.jpg)

QEU:FOUNDER ： “それでも、そこそこのマルチ外国語での推論パフォーマンスをだすからすごいよね・・・。”

![imageJRF1-12-8](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-8.jpg)

C部長 : “このように、中規模LLMでこれほど**広範な外国語サポート**を全面に出しているのはすごいです。”

### Multilingual Support
One of the standout features of Command R Plus is its extensive multilingual support. The model has been trained on text in 10 key languages: English, Spanish, French, German, Italian, Portuguese, Japanese, Ko-rean, Simplified Chinese, and Arabic. This multilingual capability enables developers to create NLP appli-cations that cater to a global audience, breaking down language barriers and fostering cross-cultural com-munication.The model’s multilingual prowess has been demonstrated through various benchmarks and evaluations. In cross-lingual natural language inference (XNLI) tasks, Command R Plus achieved an im-pressive average accuracy of 85.7% across all supported languages, surpassing the performance of many monolingual models. Similarly, in machine translation tasks, the model exhibited remarkable fluency and semantic preservation, with BLEU scores exceeding 40 for most language pairs.
---
Command R Plus の際立った特徴の 1 つは、広範な多言語サポートです。このモデルは、英語、スペイン語、フランス語、ドイツ語、イタリア語、ポルトガル語、日本語、韓国語、中国語 (簡体字)、アラビア語の 10 の主要言語のテキストでトレーニングされています。この多言語機能により、開発者は世界中のユーザーに対応する NLP アプリケーションを作成し、言語の壁を取り払い、異文化コミュニケーションを促進することができます。このモデルの多言語能力は、さまざまなベンチマークと評価を通じて実証されています。クロスリンガル自然言語推論 (XNLI) タスクでは、Command R Plus はサポートされているすべての言語で 85.7% という優れた平均精度を達成し、多くの単一言語モデルのパフォーマンスを上回りました。同様に、機械翻訳タスクでは、モデルは優れた流暢性と意味保持を示し、ほとんどの言語ペアで BLEU スコアが 40 を超えました。

QEU:FOUNDER ： “H語（↓）も、サクッと出るらしいよ。”

![imageJRF1-12-9](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-9.jpg)

C部長 : “どうやったのかなぁ？”

![imageJRF1-12-10](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-10.jpg)

QEU:FOUNDER ： “動画によると、かなり**プロンプトの設計に工夫した**らしいよ。”

![imageJRF1-12-11](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-11.jpg)

QEU:FOUNDER ： “だから回答が簡単（↑）になりました。結局は、**「良しあし」、好みの問題**だと思うんですよ。もし、１つの言語しか使わない場合であれば、このような工夫は不要です。ただし、現代では多言語を使う必要は必ずでてきます。組織ではもちろん、個人でも複数言語は必要ですよ。”

![imageJRF1-12-12](/2024-05-28-QEUR23_PHI3SFBQ10/imageJRF1-12-12.jpg)

C部長 : “我々が昔、**dolly-15kを改造した目的と同じ**ですね。”

QEU:FOUNDER ： “我々のデータセット(↑)を使ってAya-23-8Bをfinetuneすると、より効果がでてくるんじゃないかなあ・・・。ああ・・・。Cohereの**Production_keyが欲しい**・・・。”

