---
title:QEUR23_PHI2SFT11: Translationレコードを追加してSFT学習をする
date: 2024-04-10
tags: ["QEUシステム", "メトリックス", "Python言語", "LLM", "データセット", "Fine-tuning", "イノベーション","PHI-2"]
excerpt: LLMのファインチューニングを最適化する
---

## QEUR23_PHI2SFT11: Translationレコードを追加してSFT学習をする

### ～ BONSAIから、未来の世界が見える(中間まとめ) ～

D先生（設定年齢65歳） ： “まだまだ我々高齢者による、**「ゆるいLLMモデル構築の試み」**はつづいております。さて、前回のタスクはデータセットに分類属性（カテゴリ）を加えました。”

![imageJRP2-12-1](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-1.jpg)

D先生（設定年齢65歳） ： “そうすると、推論の結果が少しだけ進歩を見ました。それでは、その次はなにか新しいことをしたいのですが・・・。さて、今回のBONSAIのタスクは？”

![imageJRP2-12-2](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-2.jpg)

QEU:FOUNDER（設定年齢65歳）  ： “すでに小生が予告したように、Translationのデータの追加、そしてC語の学習レコードの追加です。ただし、その両方のレコード数も非常に微量です。”

![imageJRP2-12-3](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-3.jpg)

QEU:FOUNDER ： “今回は、あくまでtranslationデータを追加した予備アクションです。これで、どの程度の改善がみられるかがわかればいいんです。あくまで、LLMモデルの品質と性能のほとんどはPhi-2に依存しています。このモデルはMITしばりなので大変に魅力的なのですが、あまりに軽量なのがデメリットになるのは避けられません。”

![imageJRP2-12-4](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-4.jpg)

### （重要：MITライセンスへのリンク：これからは、ず～っと使うよ）

###[(クリックしてね！)](https://opensource.org/license/MIT)

D先生（設定年齢65歳） ： “さて、SFT学習の結果をみてみましょう。今回は、プログラムはほとんど同じなので、別に紹介すべき部分もありませんね。最初の推論をドン！！じゃなかった。SFT学習の結果をみていましょう。”

![imageJRP2-12-5](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-5.jpg)

QEU:FOUNDER（設定年齢65歳）  ： “あれ？SFT学習損失こそ低いのですが、前回までのような**「素直な単調な減少傾向」**にならなくなりました。ひょっとしたら、データの中に矛盾（バグ）があるのかもしれません。”

![imageJRP2-12-6](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-6.jpg)

D先生（設定年齢65歳） ： “まあ、より学習のレベルが上がったという風に好意的に評価しましょう。それでは、個別の推論にうつります。今度こそ、LLMが「Jでもっとも高い山」という問いに答えられるのか？”

![imageJRP2-12-7](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-7.jpg)

D先生（設定年齢65歳） ： “やっぱりLLMが事前に学習したJ語のデータの中に答えがないとダメなんでしょうね。次は、前回はかなりうまく行った首都の質問事例を見てみましょう。”

![imageJRP2-12-8](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-8.jpg)

QEU:FOUNDER  ： “さらなる進歩がみられますが、繰り返しが見られるのには閉口しますね。次は、この対策を打ってみたいです。さらに、A国の事例を見てみましょう。”

![imageJRP2-12-9](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-9.jpg)

D先生 ： “おしい・・・。**ウォントン**か・・・。”

QEU:FOUNDER  ： “多分、LLMはE語の情報から回答を出したのでしょう。ただし、LLMにはカナカナ化のノウハウがないようです。これは、ファインチューニング程度ではうまく治らないと思います。それでは、着眼点を変えてC語を使って予測をしましょう。”

![imageJRP2-12-10](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-10.jpg)

D先生 ： “C語では、ごく少量の学習レコードの追加でも、かなりのレベルの予測ができるようです。おそらく、このLLMでは、J語よりもC語がうまく学習されているようです。じゃあ、次は翻訳に行ってみましょう。J->E方向から始めましょう。”

![imageJRP2-12-11](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-11.jpg)

QEU:FOUNDER  ： “今回の追加したレコードは少ないとはいえ、J->E方向の翻訳の可能性については否定的になるなぁ・・・。あきらめて**C語で翻訳をやるべき**かもしれません。気持ちを取り直して、E->Jの方向をやってみましょう。”

![imageJRP2-12-12](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-12.jpg)

D先生 ： “う～ん・・・。E->J方向の翻訳には、少しだけ希望があります。まあ、それにしてもこのLLM(Phi-2)のJ語の学習量の少なさには愕然ときますね。はぁ・・・。BONSAI（盆栽）プロジェクトという名前は言い得て妙だ。私にも必然が見えてきた。ここらへんでPhi-2の限界が見えてきたかな・・・。”

QEU:FOUNDER  ： “まだ改良の余地は、少しだけありですよ。次はC語の翻訳のレコードも少量だけ追加しましょう。C語の学習データを取り込むことができれば、2バイト文字の情報が充実するかもしれません。**そうすればC語でJ語を補うこともできるかもしれない。**”

D先生 ： “あとはいよいよReasoningを改造するかですよね。・・・そういえば、今回の学習データはHuggingface（HF）に載せるんですか？”

QEU:FOUNDER ： “（HFへのデータのアップロード）は、OKですよ。皆さんが、このおもちゃ（BONSAI）を使って、我々のように**「ゆる～いプロジェクト」をエンジョイ**していただければ嬉しいですね。自分の好みに改造し、さらにはバグが見つかるともっと良し！さあ、我々も次のステップに進めましょう。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER ： “次は、データの追加とReasoning の小改造（多分・・・）ですね。非常に小さな改造だけです。”


## ～ まとめ ～

### ・・・ ここで一度、中間まとめに入りましょう ・・・

QEU:FOUNDER ： “実は、このデータセット（↓）の由来はALPACAなのですが、オリジナルにはinput欄の「私はギリシャに行きたい」という文はなかったんです。”

![imageJRP2-12-13](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-13.jpg)

C部長 : “えっ！？だったら、creativeになっちゃうじゃないですか（笑）。”

QEU:FOUNDER ： “creativeって、インプット情報によるアウトプットへの拘束が最小であり、出力文がまともでさえあれば、それだけでOKですからね。ですから、Creative類は言語モデルの学習としては効率がいいとはいえないと思います。小生はここでは、**「LLM（大規模言語モデル）って、こんなに自由度が高いものだ！」**と言いたかったのです。今しがた流行中の「大きなLLMを買って満足満足・・・」っていうわけにはいかないものなんです。本質的に・・・。”

C部長: “ただし、それはリテラシーが高い人（ユーザー）にとってはね。”

QEU:FOUNDER ： “コミュニケーション（の良し悪し）は聞き手（ユーザー）が決めるんです。それが、BONSAIプロジェクトの本質です。LLMは、すごく近い将来において、若い人のリテラシーをとてつもなく改善させますよ！ただし、今、世の中の人々が考えている感じで、その革命は起きるとは言えないです。”

![imageJRP2-12-14](/2024-04-10-QEUR23_PHI2SFT11/imageJRP2-12-14.jpg)

QEU:FOUNDER ： “AIが人間から仕事を奪う、(人間が機械に)置き換わるというものはある程度はあります。しかし、それ以上に、**「AIが人間（若者）を育てる」という形になる**と思います。**AIは若者を超人に育てる**・・・。”

C部長 : “超人！？いわゆるスーパーマンのこと？”

QEU:FOUNDER ： “おそらく、**ニーチェのいう超人**じゃない？我々の常識をぶっ飛ばしてしまうパワーを持った人たちの事です。彼らは、もはや学習のために別に授業に出ていく必要もないです。自分の興味のあることを見つけて、それを補強するためにLLMを学習させていくだけでいい・・・。”

**（カテゴリ分類のガイドライン）**

- Open_qa:（最も確からしい）答えが1つだけある。答えの内容はLLMから参照される。
- Closed_qa: （最も確からしい）答えが1つだけある。答えの大部分は質問の内容から得られる。
- Classification: 答えが1つだけある。答えの大部分は質問の内容から得られる。
- Brainstorming:答えが複数ある。答えの内容はLLMから参照される。
- Creative: 答えという概念自体がない。答えの内容はLLMから参照される。
- Translation: （最も確からしい）答えが1つだけある。答えの内容はLLMから参照される。
- Question to question: 答えという概念自体がない。答えの内容はLLMから参照される。

C部長 : “好奇心が質問を育て、**その質問への答えが新たな質問を生むという連鎖が加速する**わけです。最終的には、学校の期末テストっていらなくなるんじゃないですかね?”

QEU:FOUNDER ： “多分、その手のテストが必要となるのは、あくまで**中学まで**でしょう。このように、教え方、そして学び方が近い将来に大きくかわるんでしょうね。”

C部長: “信じられないくらいの知識を持っている人が次々と生まれてきます。”

QEU:FOUNDER ： “もちろん。ついでに補足すると、さらに強烈な行動力と創造力を併せ持った人が生まれます。あとは、若い人だけじゃなく、**高年齢の人でも同じことが可能です**。たぶん、これから高齢者は老いてさらに伸びる人と、伸びなくなる人が**極端に分かれていく**と思います。LLMって、面白いですよ。是非、遊んでみてください。小生の言っていることの意味が分かるようになるから・・・。”

