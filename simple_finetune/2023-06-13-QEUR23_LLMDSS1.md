---
title: QEUR23_LLMDSS1:　閑話休題～データセットの開発はいろいろタイヘン（前編）
date: 2023-06-13
tags: ["QEUシステム", "メトリックス", "Python言語", "LLM", "データセット", "Fine-tuning", "イノベーション"]
excerpt: LLMのファインチューニングを最適化する
---

## QEUR23_LLMDSS1:　閑話休題～データセットの開発はいろいろタイヘン（前編）

##～　苦あれば、楽ある？　～

D先生 ： “我々がやろうとしているのがミニLLM（大規模言語モデル）なんだが、それでも大変な規模ですね。今回の予備実験（！）で作成したブログだけでも、かなりの数量になりました。”

[linkcard](https://qeuslife.blogspot.com/2023/06/what-is-post-capitalism-what-is.html)

QEU:FOUNDER ： “まあ、これでも全然、(学習データの)量が少ないですよ。ちなみに学習データ採取を客観的（**バイアスなし**）に、全方位的にやろうとなると、こういうやり方がいちばんいいからね。ちょっと気を抜くと**ハルシネーション（hallucination）**が起きちゃうから・・・。”

D先生 ： “**ハルシネーション**って、なんでしたっけ・・・。”

###(title)
人工知能の幻覚 (ハルシネーション)

###(original)
###(joutai)
人工知能(AI)の幻覚（hallucination、ハルシネーション）は人工知能が学習したデータからは正当化できないはずの回答を堂々とする現象である。例えば、テスラの収益に関する知識がないチャットボットがこの現象に陥ると、もっともらしいと判断したランダムな数字（130.6億ドルのような）を内部的にピックアップして、間違っているにもかかわらずテスラの収益は130.6億ドルだと繰り返すようになる。そしてこのとき、人工知能の内部ではこの数字が自身の創造の産物だということに気付いている兆候がみられない。
こうした現象は精神医学における人間の幻覚とのアナロジーからその名が付けられている。ただし人間にとっての幻覚は「対象なき知覚」とも呼ばれ、感覚器官を通じて知覚している「対象が存在しないにもかかわらず真の知覚と区別できない知覚体験をすること」が一般的な定義とされる。それに対して人工知能の幻覚とは、どのような学習データとも整合しない回答をAIが堂々とすることである。

###(summary)
###(joutai)
人工知能(AI)においての幻覚とは、学習したデータからは正当化できない回答を堂々とする現象である。例えば、テスラの収益に関する知識がないチャットボットがこの現象に陥ると、もっともらしいと判断したランダムな数字を**内部的にピックアップして**発言するようになる。このような幻覚は人間の幻覚と類似しているが「対象なき知覚」であることと異なり、どのような学習データとも整合しない回答をAIが堂々とすることを指す。

D先生 ： “これ（↑）は、例によってWikiからの抽出ですね。ここで、Summaryの文では**「ＡＩで自動まとめ」をさせている**んですよね。私としては、基本、Summaryだけを読んでおけばいいです。う～ん・・・。要するに、**AIのハルシネーションは「知識不足」からおきる**ようですね。”

QEU:FOUNDER ： “知識が不足するので、**ＡＩが情報の穴埋めのために頭の中の情報を「適当にピックアップしてしまう」**というのが問題です。・・・で、どうして、そんなに簡単に「ピックアップできる」の？”

![imageJRL5-2-1](/2023-06-13-QEUR23_LLMDSS1/imageJRL5-2-1.jpg)

D先生 ： “ん？FOUNDERは、**ビー玉を見ながら**考えてみた・・・。”

QEU:FOUNDER ： “言葉がAIに適当にピックアップされるということは、すなわち、**その言葉（単語、トークン）がバラバラになっている**んじゃないかな？言葉がつながっていないという・・・。そう単語って、往々にして**「固有名詞」**になることが多い。特に、数字はバラバラな情報の典型です。”

![imageJRL5-2-2](/2023-06-13-QEUR23_LLMDSS1/imageJRL5-2-2.jpg)

D先生 ： “逆に言うと、固有名詞をなるべくつくらずに、あえて普通名詞に変化させるのが良いですね。その意味で、**常体を使わず、(QEU)敬体を極力使う**のが今回の工夫なんですよね。

### (title)　常体(joutai)とは

(keitai)　「だ・である調」は常体と呼ばれ、敬語を用いない普通の文章様式とされています。 文章を断定調にすることにより、より説得力のある文章になるのが特徴です。 そのため、正しい事実や強い意思を伝える際に適しています。
日本でたまに見られる「悪文」には、**自己流に漢字をつなげて長句にさせる**例もみられます。それらは、LLMのトークン学習に負担をかけるため日本語のテキストの学習精度を下げる理由の一つであるとも考えられます。

### (title)　敬体(keitai)とは

(keitai)　「です・ます調」は敬体と呼ばれ、文字通り「です」「ます」で終了する文体です。相手に語りかけるような文章になるため、読みやすく親しみやすい文章になるのが特徴です。
そのため、会話を文字にするのに適しています。さらに、QEUシステムではLLM（大型言語モデル）におけるコーパス定義の負担を減らすために、**体言止めをなくす、主語を加える、適度に前置詞を追加する**などの作業も加えます。

QEU:FOUNDER ： “**固有名詞を普通名詞にするのは良し悪し**なんだけどね・・・。ここまではアイデアとしてはいいのだが・・・。でも、これから作るモデルの材料となっているWikiにおける歴史関連の文章の現実はこんな感じなんだよね。ドン！！”

### (title)
ヨハネス・ゲンスフライシュ・ツア・ラーデン・ツム・グーテンベルクのヨハネス・グーテンベルク

### (original)
(joutai)
ヨハネス・ゲンスフライシュ・ツア・ラーデン・ツム・グーテンベルク（ドイツ語: Johannes Gensfleisch zur Laden zum Gutenberg、1398年頃 - 1468年2月3日）はドイツ出身の金細工師、印刷業者である。印刷に改良を加えた活版印刷技術の発明者といわれ、広く知られている。
グーテンベルクの古い記録は裁判記録以外ほとんどなく、活版印刷技術の真の発明者は誰かという論争が古くから行われてきたが、グーテンベルクとする説が最も有力である。1445年までに活版印刷技術を考案し、その機器の実用に成功して、自ら印刷業・印刷物出版業を創設したといわれる。金属活字を使った印刷術を発明したことで印刷革命が始まり、それが一般に中世で最も重要な出来事の1つとされている。活版印刷はルネサンス、宗教改革、啓蒙時代、科学革命の発展に寄与した。
1439年頃にヨーロッパで初めて活字による印刷を行った。活字量産方法の発明、油性インクの採用、当時使われていた農耕用スクリュープレスのような木製印刷機の採用など、様々な面で印刷に貢献している。真の画期的発明といえるのはそれらを組み合わせて実用的システムとしたことであり、それによって本の大量生産を可能にし、印刷業者にとっても読者にとっても経済的に成り立つようにした。グーテンベルクの活字生産方法の目新しい点は、古くから活字合金の発明とパンチ法と呼ばれる鋳造技法といわれていた。紙をいくつも並べて大量生産を目指すために一般人協力の元たくさんの試行錯誤が行われた。 それまでヨーロッパでの本の生産は手書きでの「書き写し」か木版印刷であり、活版印刷はヨーロッパでの本生産に一大変革を起こした。活版印刷具は急速にヨーロッパ各地に普及し、さらに世界中に広まっていった。印刷技術は羅針盤、火薬とともに「ルネサンス三大発明」の一つにあげられる。

### (summary)
(joutai)
ヨハネス・ゲンスフライシュ・ツア・ラーデン・ツム・グーテンベルクは、ドイツ出身の金細工師、印刷業者である。彼は活版印刷技術の発明者といわれ、その機器の実用に成功した。活版印刷は、ルネサンス、宗教改革、啓蒙時代、科学革命の発展に寄与した。彼の活字生産方法は、古くから活字合金の発明とパンチ法と呼ばれる鋳造技法といわれていた。彼は、本の大量生産を可能にし、印刷業者にとっても読者にとっても経済的に成り立つようにした。活版印刷は、ヨーロッパでの本生産に一大変革を起こした。

D先生 ： “ははは・・・。「ヨハネス・ゲンスフライシュ・ツア・ラーデン・ツム・グーテンベルク」 ・・・。”

QEU:FOUNDER ： “こんな固有名詞って困るよね・・・。・・・でも、グーテンベルグ関連のコーパス（文書データ）って、学習済み（Pre-train）の欧米データには必ずあります。**それらの既存のデータと我々が提供するFine-tuneのデータをどのようにつなげるのかが難しい**んだよね。”

D先生 ： “一応は手はうっているんでしょ？”

QEU:FOUNDER ： “できるだけのことをやっていますよ。それにしても、今回やってみて**「ビックデータ」が如何にいい加減なモノ**だとわかってきました。”

![imageJRL5-2-3](/2023-06-13-QEUR23_LLMDSS1/imageJRL5-2-3.jpg)

D先生 ： “ヴァイマルって・・・。「ワイマール」じゃないの？昔、高校で習ったんだけど・・・。”

QEU:FOUNDER ： “LLMが使うビッグデータの多くはWikiからとってきているんですが、かなり作者によって癖があります。このような状態で、学習をつかって本当に**「（ヴァイマルとワイマールの）マッチング」が可能なのかな**・・・。”

D先生 ： “英語版のwikiは、それほど重症じゃないんでしょうね。”

QEU:FOUNDER ： “あとは、GPT4みたいに巨大なLLMの場合だと、**パラメタが力づくで押さえつける**んでしょうね。最近、LLM界隈では学習されるデータセット(DS)の品質についての再評価が起こっており、**DS品質をよくすると学習に必要なDSサイズが小さくなる**ことがわかったんです。”

D先生 ： “FOUNDERがやっているのが、それです。”

QEU:FOUNDER ： “すごく手間がかかるよ。・・・でも、結構楽しい・・・。”

D先生 ： “えっ！？楽しいの！？”

QEU:FOUNDER ： “それはね・・・。次回につづく・・・。”



## ～　まとめ　～

C部長 : “最近、景気がいいんでしょ？”

![imageJRL5-2-4](/2023-06-13-QEUR23_LLMDSS1/imageJRL5-2-4.jpg)

QEU:FOUNDER ： “景気がいいの？そうなんだ・・・。”

C部長 : “そこに、(株価)数字が出ているじゃないですか！！”

![imageJRL5-2-5](/2023-06-13-QEUR23_LLMDSS1/imageJRL5-2-5.jpg)

QEU:FOUNDER ： “あの数字って、**「重み(WEIGHT)」で形成されている**って知ってる？まあ、産業構造も時間とともに変わるのでしょうがないがね。今、一番の重みをもっているのは、あの会社（↓）・・・。”

![imageJRL5-2-6](/2023-06-13-QEUR23_LLMDSS1/imageJRL5-2-6.jpg)

C部長 : “なるほどね・・・。”

QEU:FOUNDER ： “景気の気は、気分の気・・・（笑）。”

