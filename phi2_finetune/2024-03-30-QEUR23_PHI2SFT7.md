---
title:QEUR23_PHI2SFT7: PromptEngineering～Reasoningを使ったLLM学習(Finetuning)
date: 2024-03-30
tags: ["QEUシステム", "メトリックス", "Python言語", "LLM", "データセット", "Fine-tuning", "イノベーション","PHI-2"]
excerpt: LLMのファインチューニングを最適化する
---

## QEUR23_PHI2SFT7: PromptEngineering～Reasoningを使ったLLM学習(Finetuning)

## ～ 「ほんの少し」だけの進歩です ～

D先生（設定年齢65歳） ： “あたらしいデータセットが出来たんでしょ？Finetuningをしてみましょう！”

![imageJRP2-8-1](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-1.jpg)

QEU:FOUNDER（設定年齢65歳）  ： “じゃあ、やってみましょうか・・・。プログラムをドン！”

```python
# ---
# プロンプト変換用の関数(Batch)
def formatting_prompts_func(examples):
    output_text = []
    for i in range(len(examples["instruction"])):
        instruction = examples["instruction"][i]
        input_text = examples["input"][i]
        response = examples["output"][i]

        if len(input_text) >= 2:
            text = f'''Below is an Instruction that describes a task, paired with a Context that provides further information. Write a Response that appropriately completes the request.
            
            ### Instruction:
            {instruction}
            
            ### Context:
            {input_text}
            
            ### Response:
            {response}
            '''
        else:
            text = f'''Below is an Instruction that describes a task. Write a Response that appropriately completes the request.
            
            ### Instruction:
            {instruction}
            
            ### Response:
            {response}
            '''
        output_text.append(text)
    return output_text

```

QEU:FOUNDER ： “ちなみに、今回もMITモデルです。我々の今回のプロジェクトは「ぜ～んぶ」ね・・・。”

![imageJRP2-8-2](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-2.jpg)

**（重要：MITライセンスへのリンク：これからは、ず～っと使うよ）**

###[(クリックしてね！)](https://opensource.org/license/MIT)

D先生 ： “あれ？このプログラムは前回のものと同じですよ？”

![imageJRP2-8-3](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-3.jpg)

QEU:FOUNDER ： “まずは、データセットが変わったことによる比較です。この実行結果（↑）と、つづく**「Reasoningを使った」**実行結果を比較しようという試みです。”

**（これは、普通のプロンプトです。推論方式A）**

```python
# ---
# プロンプトを生成する
instruction = "日本でもっとも高い山はどこですか？"
input_text = ""
examples = [instruction, input_text]
prompt = create_prompts_func(examples)
print(prompt)

# <|system|>Wonder Woman is a warrior princess of the Amazons with a strong sense of justice and a mis-sion.
# ワンダーウーマンは、強い正義感と使命感を持ったアマゾン族の戦士プリンセスです。
#<|user|> What motivates you to fight for peace and love? 
# 平和と愛のために戦う動機は何ですか?
#<|assistant|>
# ---
pipe = pipeline(task="text-generation", model=model, tokenizer=tokenizer, max_length=300)
result = pipe(prompt)
print(result[0]['generated_text'])

```

![imageJRP2-8-4](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-4.jpg)

D先生（設定年齢65歳） ： “なるほど、そういう意図でしたか・・・。**従来のプロンプトで推論をやってみると、LLMからの出力に「例の繰り返し病」が再発してしまいました。**そういえば、もう一つの推論方式がありましたね。”

**（これは、普通のプロンプトです。推論方式B）**

```python
def generate_text(query):
    inputs = tokenizer(query, 
                       return_tensors="pt", 
                       return_attention_mask=False).to('cuda')
    outputs = model.generate(**inputs, max_length=200)
    text = tokenizer.batch_decode(outputs)[0]
    return text

generated_text = generate_text(prompt)
print(generated_text)

```

![imageJRP2-8-5](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-5.jpg)

QEU:FOUNDER（設定年齢65歳）  ： “結論をいうと、前回と同様に推論パフォーマンスが悪いです。じゃあ、これからPrompt Engineeringを活用して、Reasoningを付けてみましょう。プログラムをドン！！”

```python
# ------
# プロンプト変換用の関数(Batch: For Reasoning)
def formatting_prompts_func(examples):
    # ---
    sys_message = "You are AI assistant who is good at multilingual support. Switch the answer lan-guage depending on the user."
    #sys_message = "あなたは多言語対応が得意なAIアシスタントです。ユーザーに応じて回答する言語を切り替えます。"
    # ---
    output_text = []
    for i in range(len(examples["instruction"])):
        instruction = examples["instruction"][i]
        input_text = examples["input"][i]
        reasoning = examples["reasoning"][i]
        response = examples["output"][i]
        # ---
        if len(input_text) >= 2:
            text = f'''
            <|system|>{sys_message}\n<|instruction|>{instruction}\n<|context|>{input_text}\n<|reasoning|>{reasoning}\n<|response|>{response}<|endoftext|>
            '''
        else:
            text = f'''
            <|system|>{sys_message}\n<|instruction|>{instruction}\n<|reasoning|>{reasoning}\n<|response|>{response}<|endoftext|>
            '''
        output_text.append(text)
    return output_text

```

D先生 ： “なるほど、System promptも明らかになって、今回のprompt engineeringの全貌が見えてきました。これでも、少し「安易な」感じが・・・。”

QEU:FOUNDER  ： “確かに、これでも「安易」なんだが、これでも効くとなればすごいでしょ？さて、学習損失は以下のようになりました。”

![imageJRP2-8-6](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-6.jpg)

D先生 ： “ほう・・・。前回よりも学習損失が減りましたね。”

QEU:FOUNDER ： “学習損失とは参考にしか過ぎないが、前回より下がったということは「それなりに期待できる」でしょ？じゃあ、肝心の推論テストをやってみましょう。”

**（推論のAタイプ）**

![imageJRP2-8-7](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-7.jpg)

**（推論のBタイプ）**

![imageJRP2-8-8](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-8.jpg)

D先生 ： “ついに回答から**白山がでました**か・・・。これには驚きました。入力したプロンプトには、この単語はありません。少しだけ、前に動いているように思います。。”

QEU:FOUNDER（設定年齢65歳）  ： “他の事例も見てみましょう。”

**（推論のAタイプ）**

![imageJRP2-8-9](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-9.jpg)

**（推論のBタイプ）**

![imageJRP2-8-10](/2024-03-30-QEUR23_PHI2SFT7/imageJRP2-8-10.jpg)

D先生 ： “これも全然だめです。それでも米国という言葉が出てきました。LLMの頭が動いている兆しがあります。Reasoningなしの場合と比較すると、「ヨチヨチ歩き」ながらも進歩がみられています。LLMがJ国語のデータベースを読み込んで解釈をしたいという意図が見えるんです。”

QEU:FOUNDER  ： “今回は面白かった？Phi-2って、おそらくJ国語の言語データをほとんど学習していないんです。だから、このままでは良い答えが出てこないんです。”

D先生 ： “確かに今回のトライアルは面白いんですが。う～ん・・・。やりたいことがたくさんありすぎて困る・・・。”

QEU:FOUNDER ： “小生もそうです。やりたいことがありすぎて、体がついていっていません。今回は、ゆる～いプロジェクトです。次に進めましょう。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER ： “次はもうちょっとだけデータセットを改善し、かつ増量しましょう。”


## ～ まとめ ～

QEU:FOUNDER ： “最近は、インターネットの情報が多くなって1つの事柄をいろいろな角度から見ることができるようになりました。”

[![MOVIE1](http://img.youtube.com/vi/shy8cw2k1ak/0.jpg)](http://www.youtube.com/watch?v=shy8cw2k1ak "松井一郎×橋下徹が本音トーク【スナック松井】万博の開催意義")

C部長 : “**とある地域のスーパースターの競演**（↑）ですね。”

QEU:FOUNDER ： “これを、「ものの見方」を変えればこうなる（↓）そうです。”

[![MOVIE2](http://img.youtube.com/vi/fjkXn7V15B8/0.jpg)](http://www.youtube.com/watch?v=fjkXn7V15B8 "維新が推し進める万博に橋下徹「1兆ぐらいええやん」")

C部長 : “おお、こうなるのか・・・。”

QEU:FOUNDER ： “さらに、他の角度からはこう（↓）見えるようです。。”

[![MOVIE3](http://img.youtube.com/vi/DcDu0QLiFoU/0.jpg)](http://www.youtube.com/watch?v=DcDu0QLiFoU "西谷文和 路上のラジオ 第175回 藤永のぶよさん「中止しかないお粗末万博」")

C部長 : “やっぱり、物事は立体的に見ないといけませんね。”

QEU:FOUNDER ： “人生、一生勉強だなァ・・・。”

