---
title:QEUR23_PHI2SFT5: 最も基本的なFinetuning
date: 2024-03-23
tags: ["QEUシステム", "メトリックス", "Python言語", "LLM", "データセット", "Fine-tuning", "イノベーション","PHI-2"]
excerpt: LLMのファインチューニングを最適化する
---

## QEUR23_PHI2SFT5: 最も基本的なFinetuning

## ～ 注意：第一回のFinetuneはめでたく失敗です ～

QEU:FOUNDER ： “前回の予告どおり、今回は簡単なFinetuneでもやってみましょう。”

![imageJRP2-5-1](/2024-03-23-QEUR23_PHI2SFT5/imageJRP2-5-1.jpg)

**（重要：MITライセンスへのリンク：これからは、ず～っと使うよ）**

###[(クリックしてね！)](https://opensource.org/license/MIT)

D先生 ： “これは感慨深い・・・。QEUプロジェクトも、これほど高度のことをやることになろうとは・・・。”

QEU:FOUNDER ： “高度ねえ・・・。確かに、すごいことをやっているんだが、使っている我々には見えないです。はっきり言って、他の機械学習のプログラムを作るよりも簡単なくらいです。それも**Huggingface様のおかげ**なんですが・・・。”

D先生（設定年齢65歳） ： “今回のプログラムで、特に参考にした事例はないんですか？”

![imageJRP2-5-2](/2024-03-23-QEUR23_PHI2SFT5/imageJRP2-5-2.jpg)

QEU:FOUNDER（設定年齢65歳）  ： “ちゃんと検索すればわかるけども、似たようなプログラムは山ほどあります。使ってみてプログラムからエラーがでるのか、出ないのかの差だけです（笑）。それでは、プログラムをドン・・・！！”

```python
# ----
# パッケージの呼び込み
# ----
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    HfArgumentParser,
    TrainingArguments,
    pipeline,
    logging,
)
from peft import (
    LoraConfig,
    PeftModel,
    prepare_model_for_kbit_training,
    get_peft_model,
)
import os, torch
from datasets import load_dataset
from trl import SFTTrainer

base_model = "microsoft/phi-2"
dataset_name = "QEU/databricks-dolly-16k-line_ja-4_of_4"
new_model = "dolly_improved4_4"

# ----
# データセットを読み込む
# ----
#Importing the dataset
dataset = load_dataset(dataset_name, split="train[0:1000]")
dataset[100]
```

D先生 ： “あれ？我々が以前作成したdolly15kの改造版を使っていますね。”

![imageJRP2-5-3](/2024-03-23-QEUR23_PHI2SFT5/imageJRP2-5-3.jpg)

QEU:FOUNDER  ： “このDBは、J国語が主体に使われています。さらに、**E語のコンテンツと結合しやすいように文体が工夫されている**んです。もし、この内容を詳しく知りたかったらHuggingfaceのデータにアクセスしてください。”

D先生 ： “これを使ったファインチューニングでJ国語のLLMモデルに変化してくれるかなあ・・・。”

```python
# ---
# プロンプト変換用の関数(Batch)
def formatting_prompts_func(examples):
    output_text = []
    for i in range(len(examples["instruction"])):
        instruction = examples["instruction"][i]
        input_text = examples["input"][i]
        response = examples["output"][i]

        if len(input_text) >= 2:
            text = f'''Below is an Instruction that describes a task, paired with a Context that provides further information. Write a Response that appropriately completes the request.
            
            ### Instruction:
            {instruction}
            
            ### Context:
            {input_text}
            
            ### Response:
            {response}
            '''
        else:
            text = f'''Below is an Instruction that describes a task. Write a Response that appropriately completes the request.
            
            ### Instruction:
            {instruction}
            
            ### Response:
            {response}
            '''
        output_text.append(text)
    return output_text

```

QEU:FOUNDER ： “さあね・・・。今回使っているプロンプトはとてもシンプルなもの（↑）ですから・・・。”

D先生 ： “せっかく発掘したReasoningのスキームを使わないのですか？”

QEU:FOUNDER ： “今回はファインチューン編の最初だからね。あまり手間を掛けたくないんですよ・・・。おれでは、つづきにいきましょう。”

```python
# ---
# Load base model(Phi-2)
bnb_config = BitsAndBytesConfig(  
    load_in_4bit= True,
    bnb_4bit_quant_type= "nf4",
    bnb_4bit_compute_dtype= torch.bfloat16,
    bnb_4bit_use_double_quant= False,
)

model = AutoModelForCausalLM.from_pretrained(
    base_model,
    quantization_config=bnb_config,
    device_map="auto",
    trust_remote_code=True,
)

model.config.use_cache = False
model.config.pretraining_tp = 1

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)
tokenizer.pad_token = tokenizer.eos_token

model = prepare_model_for_kbit_training(model)
peft_config = LoraConfig(
    r=16,
    lora_alpha=16,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
    target_modules=[
        'q_proj',
        'k_proj',
        'v_proj',
        'dense',
        'fc1',
        'fc2',
    ]
)
model = get_peft_model(model, peft_config)

training_arguments = TrainingArguments(
    output_dir="./dolly_improved4_4",
    num_train_epochs=1,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=1,
    optim="paged_adamw_32bit",
    save_strategy="epoch",
    logging_steps=100,
    logging_strategy="steps",
    learning_rate=1e-4,
    fp16=False,
    bf16=False,
    group_by_length=True,
    disable_tqdm=False,
    report_to="none",
)

trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    #eval_dataset=dataset,
    peft_config=peft_config,
    max_seq_length= 2048,
    tokenizer=tokenizer,
    args=training_arguments,
    formatting_func=formatting_prompts_func,
    packing= False,
)

trainer.train()

```

D先生（設定年齢65歳） ： “一応は、FT学習されていますね。でも、すごい沢山のwarningが出てますね。”

![imageJRP2-5-4](/2024-03-23-QEUR23_PHI2SFT5/imageJRP2-5-4.jpg)

QEU:FOUNDER（設定年齢65歳）  ： “複雑なシステムなので、warningぐらいはしようがないとあきらめています・・・（笑）。多分、システムがいいように例外処理をしてくれているから大丈夫だとおもいますよ。じゃあ、次に推論にいくよ。プログラムは以前のモノで動くと思うので省略します。”

![imageJRP2-5-5](/2024-03-23-QEUR23_PHI2SFT5/imageJRP2-5-5.jpg)

D先生（設定年齢65歳） ： “あ～あ・・・。こんな簡単な質問にも答えられないんだ。”

QEU:FOUNDER ： “でも、ちゃんとJ国語が出てくれるんだネ。少し進歩しているとも言えますよ。じゃあ、ちょっと面白い実験をしてみましょう。C国語は出てくるか？”

D先生 ： “でも、J国語でファインチューニングされているからなあ・・・（笑）。”

![imageJRP2-5-6](/2024-03-23-QEUR23_PHI2SFT5/imageJRP2-5-6.jpg)

D先生 ： “こ・・・、これは・・・（笑）。これはJ語なんですかね？それともC語なんですかねえ？”

QEU:FOUNDER  ： “これで分かったことがあるんです。このAIは、自分が何語で話しているかの自覚がないんです。”

D先生 ： “もちろん、より強力かつ大型のAIならば**「何語で話す」って気にしていない**のでしょうけどね・・・。小規模の言語モデルでは、ちゃんと自覚させる必要があります。”

**The input structure is as follows:** **<|system|>sys_message\n<|prompt|>prompt\n<|reasoning|>reasoning\n<|response|>response<|endoftext|>**


QEU:FOUNDER ： “いよいよ、**「Reasoning is all you need」**を使うときがきましたね。”

### [＞寄付のお願い(click here)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER ： “またもや言語データの作り直しか。ちょっと憂鬱・・・。”


## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “質問用のAIと回答用のAIは、そのスペックが異なっていきます。それでも、phi-2のような超軽量モデルで満足する推論ができるかどうかはしらないけど・・・。”

C部長 : “今後、世の中のハードウェアのレベルがあがれば、皆が「phi-3というモデル」を普通に使えるかもしれないですね。”

QEU:FOUNDER ： “そこまで行けば、質問用AIは絶対モノになると思いますよ。そして、品質管理って、質問の体系なんですよ。皆がご存じのとおり・・・。”

![imageJRP2-5-7](/2024-03-23-QEUR23_PHI2SFT5/imageJRP2-5-7.jpg)

C部長 : “検査指示書（↑）って、結局のところは質問でできていますからね。まあ、我々管理者も**「質問」でメシを食っている**わけだ・・・。”

![imageJRP2-5-8](/2024-03-23-QEUR23_PHI2SFT5/imageJRP2-5-8.jpg)

QEU:FOUNDER ： “つまり、**「質問=管理」**であり、**「回答=製造」**という風に見るとわかりやすいですよね。近い将来には、製造員の後ろに回答AIがバックアップし、管理員の後ろで質問AIが支援する世界が見られるわけです。ホント、この世界はもうすぐきますよ。もっというと、**質問AIって人間を幸せにする能力を持っている**と思います。”

C部長 : “そうなんですか？”

QEU:FOUNDER ： “「好奇心」とは言わないが、質問が多い人って若々しいじゃないですか？**年をとると質問が出なくなっているんですよ。それは会社も同じで・・・**。”

C部長 : “イヤミですか・・・。うち（の会社）なんか、黙々と言われたことをだけをやる人間ばかりになって、活気が無くなっちゃった・・・。”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」
### オッサン（＠車中、N社検査不正について）： 「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」 
### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

D先生 : “パワハラの連続で、部下の元気を奪ってきたの自分じゃないの？”

C部長 : “あの・・・、「そういう時代」でしたので・・・（汗）。”

[![MOVIE1](http://img.youtube.com/vi/bd1nfSla4c0/0.jpg)](http://www.youtube.com/watch?v=bd1nfSla4c0 "恐怖の円安！鈴木財務大臣が驚愕のアホ発言！日銀マイナス金利解除でも円安。教科書とは真逆の減少。日米金利差だけでは説明出来ない恐ろしさ。")

QEU:FOUNDER ： “そんなことばっかりやっているから、**社会の活気が消滅し、取り返しのつかないことが起きようとしている**んですよ。小生は、ずっと前から、それらの災難を回避しようと「MITライセンスを振りかざして頑張っている」が、はたして間に合うか・・・。”

D先生: “大先輩方は、昔、あれだけ自信満々に言っていたので、**なんとかしてくれる**んじゃないんでしょうかねえ？”

QEU:FOUNDER ： “あっ、そうか・・・。小生も心配性だなあ・・・（笑）。”

